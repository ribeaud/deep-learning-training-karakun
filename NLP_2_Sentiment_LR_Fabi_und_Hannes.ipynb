{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NLP   at Karakun             Part 2     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk              \n",
    "import random\n",
    "import numpy as np\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentiment analysis with logistic \n",
    "\n",
    "We'll use the IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing/evaluation. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = []\n",
    "test_input  = []\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/imdb/train-pos.txt','r') as f:\n",
    "    for line in f:\n",
    "        train_input.append((line,1))\n",
    "f.close()\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/imdb/train-neg.txt','r') as f:\n",
    "    for line in f:\n",
    "        train_input.append((line,0))\n",
    "f.close()\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/imdb/test-pos.txt','r') as f:\n",
    "    for line in f:\n",
    "        test_input.append((line,1))\n",
    "f.close()\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/imdb/test-neg.txt','r') as f:\n",
    "    for line in f:\n",
    "        test_input.append((line,0))\n",
    "f.close()\n",
    "\n",
    "\n",
    "random.shuffle(train_input)\n",
    "random.shuffle(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = []\n",
    "train_sent    = []\n",
    "test_reviews  = []\n",
    "test_sent     = []\n",
    "\n",
    "for (words, sentiment) in train_input:\n",
    "    review_filtered = ' '.join(e.lower() for e in words.split() if len(e) >= 2)\n",
    "    train_reviews.append(review_filtered)\n",
    "    train_sent.append(sentiment)\n",
    "\n",
    "for (words, sentiment) in test_input:\n",
    "    review_filtered = ' '.join(e.lower() for e in words.split() if len(e) >= 2)\n",
    "    test_reviews.append(review_filtered)\n",
    "    test_sent.append(sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "print( len(train_reviews) , len(test_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(test_sent[i])   #  should be  0 1 1 0 1 1 0 0 1 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test= int(len(test_reviews)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 12500 12500\n"
     ]
    }
   ],
   "source": [
    "eval_reviews = test_reviews[:N_test]\n",
    "eval_sent    = test_sent[:N_test]\n",
    "test_reviews = test_reviews[N_test:]\n",
    "test_sent    = test_sent[N_test:]\n",
    "print(len(train_reviews),len(test_reviews),len(eval_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF and TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=7000, min_df=4, ngram_range=[1,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression: regression and sigmoid activation\n",
    "Now we use the document-term matrix to extract features for logistics regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit(train_reviews).transform(train_reviews)\n",
    "y_train = train_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 373319)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  373319 \n",
      "\n",
      "X_train is a very sparse matrix with  9332975000 elements in total\n",
      "          <25000x373319 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 8079943 stored elements in Compressed Sparse Row format>\n",
      "X_eval:   <12500x373319 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3771564 stored elements in Compressed Sparse Row format>\n",
      "X_test:   <12500x373319 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3720934 stored elements in Compressed Sparse Row format>\n",
      "accuracy with logistic regression on test set: 90.34 %\n",
      "  |      1      0      2 |\n",
      "--+----------------------+\n",
      "1 | <45.5%>  4.5%      . |\n",
      "0 |   5.1% <44.9%>     . |\n",
      "2 |      .      .     <.>|\n",
      "--+----------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_eval  = vectorizer.transform(eval_reviews)\n",
    "X_test  = vectorizer.transform(test_reviews)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print('Number of features: ', len(feature_names), '\\n')\n",
    "\n",
    "print('X_train is a very sparse matrix with ',X_train.shape[0]*X_train.shape[1], 'elements in total')\n",
    "print('         ', repr(X_train))\n",
    "print('X_eval:  ', repr(X_eval) )\n",
    "print('X_test:  ', repr(X_test) )\n",
    "\n",
    "from sklearn import preprocessing\n",
    "mm_scaler = preprocessing.MaxAbsScaler()\n",
    "X_train_scaled = mm_scaler.fit_transform(X_train)\n",
    "X_test_scaled = mm_scaler.transform(X_test)\n",
    "X_eval_scaled = mm_scaler.transform(X_eval)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression(max_iter=10000)\n",
    "LR.fit(X_train_scaled, y_train)\n",
    "\n",
    "cm = nltk.ConfusionMatrix(test_sent, LR.predict(X_test_scaled))\n",
    "\n",
    "print(\"accuracy with logistic regression on test set: %5.2f %%\" % \n",
    "            ((cm[1,1]+cm[0,0])/ (1.0*cm[1,1]+cm[0,0]+cm[1,0]+cm[0,1])*100) )\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.025   -->  0.90424\n",
      "C =  0.026000000000000002   -->  0.90464\n",
      "C =  0.027000000000000003   -->  0.90504\n",
      "C =  0.028000000000000004   -->  0.90512\n",
      "C =  0.029   -->  0.90544\n",
      "C =  0.030000000000000002   -->  0.90552\n",
      "C =  0.031000000000000003   -->  0.90544\n",
      "C =  0.032   -->  0.90576\n",
      "C =  0.033   -->  0.90584\n",
      "C =  0.034   -->  0.906\n",
      "C =  0.035   -->  0.90584\n",
      "bestCval =  0.034   -->  0.906\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "if True:\n",
    "    bestCval = 0\n",
    "    bestCvalParam = 0\n",
    "    for Cval in np.linspace(start=0.0250, stop=0.0350, num=11):\n",
    "        LR = LogisticRegression(max_iter=10000, C=Cval, solver='liblinear')\n",
    "        LR.fit(X_train_scaled, y_train)\n",
    "        accuracy = sum(LR.predict(X_test_scaled) == test_sent) / len(eval_sent)\n",
    "        print('C = ',Cval,'  --> ', accuracy)\n",
    "        if accuracy > bestCvalParam :\n",
    "            bestCvalParam = accuracy\n",
    "            bestCval = Cval\n",
    "    print('bestCval = ',bestCval,'  --> ', bestCvalParam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with logistic regression on test set: 90.60 %\n",
      "  |      1      0      2 |\n",
      "--+----------------------+\n",
      "1 | <45.8%>  4.3%      . |\n",
      "0 |   5.1% <44.8%>     . |\n",
      "2 |      .      .     <.>|\n",
      "--+----------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(max_iter=10000, C=bestCval, solver='liblinear')\n",
    "LR.fit(X_train_scaled, y_train)\n",
    "\n",
    "cm = nltk.ConfusionMatrix(test_sent, LR.predict(X_test_scaled))\n",
    "\n",
    "print(\"accuracy with logistic regression on test set: %5.2f %%\" % \n",
    "            ((cm[1,1]+cm[0,0])/ (1.0*cm[1,1]+cm[0,0]+cm[1,0]+cm[0,1])*100) )\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
