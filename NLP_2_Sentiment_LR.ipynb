{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to NLP   at Karakun             Part 2     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk              \n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Sentiment analysis with logistic \n",
    "\n",
    "We'll use the IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. These are split into 25,000 reviews for training and 25,000 reviews for testing/evaluation. The training and testing sets are balanced, meaning they contain an equal number of positive and negative reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = []\n",
    "test_input  = []\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/IMDb/train-pos.txt','r') as f:\n",
    "    for line in f:\n",
    "        train_input.append((line,1))\n",
    "f.close()\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/IMDb/train-neg.txt','r') as f:\n",
    "    for line in f:\n",
    "        train_input.append((line,0))\n",
    "f.close()\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/IMDb/test-pos.txt','r') as f:\n",
    "    for line in f:\n",
    "        test_input.append((line,1))\n",
    "f.close()\n",
    "\n",
    "with open('./Sentiment-Analysis-Data/IMDb/test-neg.txt','r') as f:\n",
    "    for line in f:\n",
    "        test_input.append((line,0))\n",
    "f.close()\n",
    "\n",
    "\n",
    "random.shuffle(train_input)\n",
    "random.shuffle(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_reviews = []\n",
    "train_sent    = []\n",
    "test_reviews  = []\n",
    "test_sent     = []\n",
    "\n",
    "for (words, sentiment) in train_input:\n",
    "    review_filtered = ' '.join(e.lower() for e in words.split() if len(e) >= 2)\n",
    "    train_reviews.append(review_filtered)\n",
    "    train_sent.append(sentiment)\n",
    "\n",
    "for (words, sentiment) in test_input:\n",
    "    review_filtered = ' '.join(e.lower() for e in words.split() if len(e) >= 2)\n",
    "    test_reviews.append(review_filtered)\n",
    "    test_sent.append(sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 25000\n"
     ]
    }
   ],
   "source": [
    "print( len(train_reviews) , len(test_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "1\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(test_sent[i])   #  should be  0 1 1 0 1 1 0 0 1 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_test= int(len(test_reviews)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 12500 12500\n"
     ]
    }
   ],
   "source": [
    "eval_reviews = test_reviews[:N_test]\n",
    "eval_sent    = test_sent[:N_test]\n",
    "test_reviews = test_reviews[N_test:]\n",
    "test_sent    = test_sent[N_test:]\n",
    "print(len(train_reviews),len(test_reviews),len(eval_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF and TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "...     'This is the first document.',\n",
    "...     'This is the second document.',\n",
    "...     'And the third one.',\n",
    "...     'Is this the first document?',\n",
    "... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc_matrix = vectorizer.fit_transform(corpus)\n",
    "term_doc_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 1, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 1, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_doc_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'this': 8,\n",
       " 'is': 3,\n",
       " 'the': 6,\n",
       " 'first': 2,\n",
       " 'document': 1,\n",
       " 'second': 5,\n",
       " 'and': 0,\n",
       " 'third': 7,\n",
       " 'one': 4}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary = vectorizer.vocabulary_\n",
    "vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = vectorizer.get_feature_names()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask= term_doc_matrix.toarray()[2]\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'and one the third'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(vocab[i] for i in range(len(vocab)) if mask[i] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0, 0, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['This is a test text to check the output of CountVectorizer']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression: regression and sigmoid activation\n",
    "Now we use the document-term matrix to extract features for logistics regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.fit(train_reviews).transform(train_reviews)\n",
    "y_train = train_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 73394)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  73394 \n",
      "\n",
      "X_train is a very sparse matrix with  1834850000 elements in total\n",
      "          <25000x73394 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 3410079 stored elements in Compressed Sparse Row format>\n",
      "X_eval:   <12500x73394 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 1660977 stored elements in Compressed Sparse Row format>\n",
      "X_test:   <12500x73394 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 1644444 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "X_eval  = vectorizer.transform(eval_reviews)\n",
    "X_test  = vectorizer.transform(test_reviews)\n",
    "\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print('Number of features: ', len(feature_names), '\\n')\n",
    "\n",
    "print('X_train is a very sparse matrix with ',X_train.shape[0]*X_train.shape[1], 'elements in total')\n",
    "print('         ', repr(X_train))\n",
    "print('X_eval:  ', repr(X_eval) )\n",
    "print('X_test:  ', repr(X_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression takes a regular linear regression, and applies a sigmoid to the output of the linear regression.\n",
    "\n",
    "rienear Regression:\n",
    "$$z = \\theta_0 x_0 + \\theta_1 x_1 + \\theta_2 x_2 + ... \\theta_N x_N$$\n",
    "\n",
    "Note that the $\\theta$ values are \"weights\" to be learned, 'z' is refered to as 'logits' and is input for the activation function (sigmoid): \n",
    "\n",
    "$$ h(z) = \\frac{1}{1+\\exp^{-z}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The cost function\n",
    "\n",
    "The cost function used for logistic regression is the average of the log loss across all training examples:\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m y^{(i)}\\log (h(z(\\theta)^{(i)})) + (1-y^{(i)})\\log (1-h(z(\\theta)^{(i)}))\\tag{5} $$\n",
    "* $m$ is the number of training examples\n",
    "* $y^{(i)}$ is the actual sentiment label of the i-th training example, hence $0$ or $1$.\n",
    "* $h(z(\\theta)^{(i)})$ is the model's prediction for the i-th training example.\n",
    "\n",
    "\n",
    "* All the $h$ values are between 0 and 1, so the logs will be negative. That is the reason for the factor of -1 applied to the sum of the two loss terms.\n",
    "* Note that when the model predicts 1 ($h(z(\\theta)) = 1$) and the label $y$ is also 1, the loss for that training example is 0. \n",
    "* Similarly, when the model predicts 0 ($h(z(\\theta)) = 0$) and the actual label is also 0, the loss for that training example is 0. \n",
    "* However, when the model prediction is close to 1 ($h(z(\\theta)) = 0.9999$) and the label is 0, the second term of the log loss becomes a large negative number, which is then multiplied by the overall factor of -1 to convert it to a positive loss value. $-1 \\times (1 - 0) \\times log(1 - 0.9999) \\approx 9.2$ The closer the model prediction gets to 1, the larger the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manfred\\Anaconda3\\envs\\TF-gpu\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with logistic regression on test set: 86.24 %\n",
      "  |      1      0      2 |\n",
      "--+----------------------+\n",
      "1 | <42.7%>  7.3%      . |\n",
      "0 |   6.4% <43.5%>     . |\n",
      "2 |      .      .     <.>|\n",
      "--+----------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR = LogisticRegression()\n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "cm = nltk.ConfusionMatrix(test_sent, LR.predict(X_test))\n",
    "\n",
    "print(\"accuracy with logistic regression on test set: %5.2f %%\" % \n",
    "            ((cm[1,1]+cm[0,0])/ (1.0*cm[1,1]+cm[0,0]+cm[1,0]+cm[0,1])*100) )\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C =  0.01   -->  0.88392\n",
      "C =  0.03   -->  0.88568\n",
      "C =  0.1   -->  0.88168\n",
      "C =  0.3   -->  0.87792\n",
      "C =  1.0   -->  0.872\n"
     ]
    }
   ],
   "source": [
    "for Cval in [0.01,0.03,0.1,0.3,1.0]:\n",
    "    LR = LogisticRegression(C=Cval)\n",
    "    LR.fit(X_train, y_train)\n",
    "    print('C = ',Cval,'  --> ',sum(LR.predict(X_eval) == eval_sent) / len(eval_sent) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy with logistic regression on test set: 88.14 %\n",
      "  |      1      0      2 |\n",
      "--+----------------------+\n",
      "1 | <44.0%>  6.0%      . |\n",
      "0 |   5.8% <44.1%>     . |\n",
      "2 |      .      .     <.>|\n",
      "--+----------------------+\n",
      "(row = reference; col = test)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression(C=0.03) \n",
    "LR.fit(X_train, y_train)\n",
    "\n",
    "cm = nltk.ConfusionMatrix(test_sent, LR.predict(X_test))\n",
    "\n",
    "print(\"accuracy with logistic regression on test set: %5.2f %%\" % \n",
    "            ((cm[1,1]+cm[0,0])/ (1.0*cm[1,1]+cm[0,0]+cm[1,0]+cm[0,1])*100) )\n",
    "print(cm.pretty_format(sort_by_count=True, show_percents=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "?LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
